{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [DO NOT EDIT] Header\n",
        "\n",
        "本笔记本实现了用于数字分类的感知机模型，包含超参数调优。\n",
        "所有代码必须遵循实现指南中定义的项目结构和命名约定。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# 魔法命令\n",
        "%matplotlib inline\n",
        "\n",
        "# 路径设置 - 导入此模块会自动设置Python路径\n",
        "import path_setup\n",
        "\n",
        "# 直接导入项目模块（IDE可以正确追踪）\n",
        "from load_data import load_digits_dataset\n",
        "from evaluate import eval_classification, eval_classification_with_roc\n",
        "from visualize import plot_confusion_matrix, plot_bar\n",
        "\n",
        "# Constants\n",
        "RANDOM_STATE = 42\n",
        "NOTEBOOK_BASENAME = \"part7_perceptron\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(\"../results/figures\", exist_ok=True)\n",
        "os.makedirs(\"../results/metrics\", exist_ok=True)\n",
        "\n",
        "print(\"✓ 环境设置完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Loading\n",
        "\n",
        "使用提供的API函数加载数字数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the digits dataset\n",
        "X_train, X_test, y_train, y_test, target_names = load_digits_dataset()\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of classes: {len(target_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition (Default Only)\n",
        "\n",
        "仅定义一个模型实例，使用库默认参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define default model with library defaults\n",
        "from sklearn.linear_model import Perceptron\n",
        "default_model = Perceptron(\n",
        "    max_iter=1000,\n",
        "    early_stopping=False,\n",
        "    random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Default Model)\n",
        "\n",
        "对默认参数模型执行训练，记录训练用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the default model\n",
        "start_time = time.time()\n",
        "default_model.fit(X_train, y_train)\n",
        "default_training_time = time.time() - start_time\n",
        "print(f\"Default model training time: {default_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Default Model)\n",
        "\n",
        "评估默认模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the default model\n",
        "default_metrics = eval_classification(default_model, X_test, y_test, target_names)\n",
        "print(f\"Default model accuracy: {default_metrics['accuracy']:.4f}\")\n",
        "print(f\"Default model macro F1: {default_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Default model weighted F1: {default_metrics['weighted_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Default Model)\n",
        "\n",
        "可视化默认模型结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix for default model\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_default.png\"\n",
        "plot_confusion_matrix(default_metrics['confusion_matrix'], target_names, out_png_path)\n",
        "print(f\"Default model confusion matrix saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fill Hyperparams (Tuning Spec)\n",
        "\n",
        "定义调参网格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grid for Perceptron\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Define base model with stability parameters\n",
        "base_model = Perceptron(\n",
        "    max_iter=1000,\n",
        "    early_stopping=False,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Define parameter grid (strictly follow Canvas Chapter 4)\n",
        "param_grid = {\n",
        "    'eta0': [0.0005, 0.001, 0.01]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "gs = GridSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Execute grid search\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and CV score\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"Best CV score (accuracy):\", gs.best_score_)\n",
        "\n",
        "# Get best model and evaluate on test set\n",
        "best_model = gs.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)\n",
        "print(\"Test accuracy with best params:\", test_acc)\n",
        "\n",
        "# Save variables for later use\n",
        "model = best_model\n",
        "best_params = gs.best_params_\n",
        "best_training_time = gs.cv_results_['mean_fit_time'][gs.best_index_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Tuned Model)\n",
        "\n",
        "使用最佳参数实例化第二个模型对象并训练，记录用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the best model (already done during grid search)\n",
        "print(f\"Best model trained with hyperparameters: {best_params}\")\n",
        "print(f\"Training time: {best_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Tuned Model)\n",
        "\n",
        "评估调参后模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the best model\n",
        "final_metrics = eval_classification(best_model, X_test, y_test, target_names)\n",
        "\n",
        "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {final_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Weighted F1: {final_metrics['weighted_f1']:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(final_metrics['classification_report'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Tuned Model + Param Curves)\n",
        "\n",
        "可视化调参后模型结果和性能曲线。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ① Plot confusion matrix for tuned model\n",
        "cm = final_metrics['confusion_matrix']\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_tuned.png\"\n",
        "plot_confusion_matrix(cm, target_names, out_png_path)\n",
        "print(f\"Tuned model confusion matrix saved to {out_png_path}\")\n",
        "\n",
        "# ② Plot parameter performance curves\n",
        "cv_results = gs.cv_results_\n",
        "params_list = cv_results[\"params\"]\n",
        "mean_test = cv_results[\"mean_test_score\"]\n",
        "\n",
        "# Extract data for eta0 parameter\n",
        "eta0_vals = []\n",
        "scores = []\n",
        "for i, params in enumerate(params_list):\n",
        "    eta0_vals.append(params['eta0'])\n",
        "    scores.append(mean_test[i])\n",
        "\n",
        "# Sort\n",
        "sorted_pairs = sorted(zip(eta0_vals, scores))\n",
        "eta0_vals_sorted = [p[0] for p in sorted_pairs]\n",
        "scores_sorted = [p[1] for p in sorted_pairs]\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(eta0_vals_sorted, scores_sorted, marker='o', linewidth=2, markersize=8)\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('eta0 (Learning Rate)', fontsize=12)\n",
        "ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "ax.set_title('Perceptron: Accuracy vs Learning Rate (eta0)', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__acc_vs_eta0.png\"\n",
        "plt.savefig(out_png_path, dpi=100, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Accuracy vs eta0 plot saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Persist Metrics\n",
        "\n",
        "将指标保存到指定的JSON文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create metrics dictionary\n",
        "metrics_dict = {\n",
        "    \"model_name\": \"Perceptron\",\n",
        "    \"best_hyperparams\": best_params,\n",
        "    \"accuracy\": final_metrics['accuracy'],\n",
        "    \"macro_f1\": final_metrics['macro_f1'],\n",
        "    \"weighted_f1\": final_metrics['weighted_f1'],\n",
        "    \"train_time_sec\": best_training_time,\n",
        "    \"notes\": f\"Perceptron with eta0={best_params['eta0']} achieved {final_metrics['accuracy']:.4f} accuracy\"\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file\n",
        "metrics_path = f\"../results/metrics/{NOTEBOOK_BASENAME}__metrics.json\"\n",
        "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics_dict, f, indent=2)\n",
        "\n",
        "print(f\"Metrics saved to {metrics_path}\")\n",
        "print(f\"Final metrics: {metrics_dict}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 eta0=0.01 的感知机达到了最佳性能，准确率为 0.8889。\n",
        "本模型对学习率 eta0 参数敏感，较高的学习率在该数据集上效果更好。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion (Template)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
