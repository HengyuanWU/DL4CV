{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [DO NOT EDIT] Header\n",
        "\n",
        "本笔记本实现了用于数字分类的SGD分类器模型，包含超参数调优。\n",
        "所有代码必须遵循实现指南中定义的项目结构和命名约定。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# 魔法命令\n",
        "%matplotlib inline\n",
        "\n",
        "# 路径设置 - 导入此模块会自动设置Python路径\n",
        "import path_setup\n",
        "\n",
        "# 直接导入项目模块（IDE可以正确追踪）\n",
        "from load_data import load_digits_dataset\n",
        "from evaluate import eval_classification, eval_classification_with_roc\n",
        "from visualize import plot_confusion_matrix, plot_bar\n",
        "\n",
        "# Constants\n",
        "RANDOM_STATE = 42\n",
        "NOTEBOOK_BASENAME = \"part6_sgd\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(\"../results/figures\", exist_ok=True)\n",
        "os.makedirs(\"../results/metrics\", exist_ok=True)\n",
        "\n",
        "print(\"✓ 环境设置完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Loading\n",
        "\n",
        "使用提供的API函数加载数字数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the digits dataset\n",
        "X_train, X_test, y_train, y_test, target_names = load_digits_dataset()\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of classes: {len(target_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition (Default Only)\n",
        "\n",
        "仅定义一个模型实例，使用库默认参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define default model with library defaults\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "default_model = SGDClassifier(\n",
        "    max_iter=1000,\n",
        "    random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Default Model)\n",
        "\n",
        "对默认参数模型执行训练，记录训练用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the default model\n",
        "start_time = time.time()\n",
        "default_model.fit(X_train, y_train)\n",
        "default_training_time = time.time() - start_time\n",
        "print(f\"Default model training time: {default_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Default Model)\n",
        "\n",
        "评估默认模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the default model\n",
        "default_metrics = eval_classification(default_model, X_test, y_test, target_names)\n",
        "print(f\"Default model accuracy: {default_metrics['accuracy']:.4f}\")\n",
        "print(f\"Default model macro F1: {default_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Default model weighted F1: {default_metrics['weighted_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Default Model)\n",
        "\n",
        "可视化默认模型结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix for default model\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_default.png\"\n",
        "plot_confusion_matrix(default_metrics['confusion_matrix'], target_names, out_png_path)\n",
        "print(f\"Default model confusion matrix saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fill Hyperparams (Tuning Spec)\n",
        "\n",
        "定义调参网格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grid for SGD Classifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Define base model with stability parameters\n",
        "base_model = SGDClassifier(\n",
        "    max_iter=1000,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Define parameter grid (strictly follow Canvas Chapter 4)\n",
        "param_grid = {\n",
        "    'loss': ['hinge', 'log_loss'],\n",
        "    'alpha': [1e-4, 1e-3, 1e-2]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "gs = GridSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Execute grid search\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and CV score\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"Best CV score (accuracy):\", gs.best_score_)\n",
        "\n",
        "# Get best model and evaluate on test set\n",
        "best_model = gs.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)\n",
        "print(\"Test accuracy with best params:\", test_acc)\n",
        "\n",
        "# Save variables for later use\n",
        "model = best_model\n",
        "best_params = gs.best_params_\n",
        "best_training_time = gs.cv_results_['mean_fit_time'][gs.best_index_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Tuned Model)\n",
        "\n",
        "使用最佳参数实例化第二个模型对象并训练，记录用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the best model (already done during grid search)\n",
        "print(f\"Best model trained with hyperparameters: {best_params}\")\n",
        "print(f\"Training time: {best_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Tuned Model)\n",
        "\n",
        "评估调参后模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the best model\n",
        "final_metrics = eval_classification(best_model, X_test, y_test, target_names)\n",
        "\n",
        "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {final_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Weighted F1: {final_metrics['weighted_f1']:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(final_metrics['classification_report'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Tuned Model + Param Curves)\n",
        "\n",
        "可视化调参后模型结果和性能曲线。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ① Plot confusion matrix for tuned model\n",
        "cm = final_metrics['confusion_matrix']\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_tuned.png\"\n",
        "plot_confusion_matrix(cm, target_names, out_png_path)\n",
        "print(f\"Tuned model confusion matrix saved to {out_png_path}\")\n",
        "\n",
        "# ② Plot parameter performance curves\n",
        "cv_results = gs.cv_results_\n",
        "params_list = cv_results[\"params\"]\n",
        "mean_test = cv_results[\"mean_test_score\"]\n",
        "\n",
        "# Plot alpha for each loss\n",
        "for param_key in param_grid.keys():\n",
        "    if param_key == 'alpha':\n",
        "        # Separate by loss\n",
        "        for loss_val in ['hinge', 'log_loss']:\n",
        "            alpha_vals = []\n",
        "            scores = []\n",
        "            for i, params in enumerate(params_list):\n",
        "                if params['loss'] == loss_val:\n",
        "                    alpha_vals.append(params['alpha'])\n",
        "                    scores.append(mean_test[i])\n",
        "            \n",
        "            # Sort by alpha\n",
        "            sorted_pairs = sorted(zip(alpha_vals, scores))\n",
        "            alpha_vals_sorted = [p[0] for p in sorted_pairs]\n",
        "            scores_sorted = [p[1] for p in sorted_pairs]\n",
        "            \n",
        "            # Plot\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            ax.plot(alpha_vals_sorted, scores_sorted, marker='o', linewidth=2, markersize=8)\n",
        "            ax.set_xscale('log')\n",
        "            ax.set_xlabel('alpha', fontsize=12)\n",
        "            ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "            loss_label = loss_val.replace('_', ' ').title()\n",
        "            ax.set_title(f'SGD: Accuracy vs alpha (loss={loss_val})', fontsize=14)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            loss_filename = loss_val.replace('_', '')\n",
        "            out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__acc_vs_alpha_{loss_filename}.png\"\n",
        "            plt.savefig(out_png_path, dpi=100, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            print(f\"Accuracy vs alpha ({loss_val}) plot saved to {out_png_path}\")\n",
        "    \n",
        "    elif param_key == 'loss':\n",
        "        # Plot for loss parameter - use best alpha\n",
        "        best_alpha = best_params['alpha']\n",
        "        loss_vals = []\n",
        "        scores = []\n",
        "        for i, params in enumerate(params_list):\n",
        "            if params['alpha'] == best_alpha:\n",
        "                loss_vals.append(params['loss'])\n",
        "                scores.append(mean_test[i])\n",
        "        \n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.bar(range(len(loss_vals)), scores, tick_label=loss_vals)\n",
        "        ax.set_xlabel('loss', fontsize=12)\n",
        "        ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "        ax.set_title(f'SGD: Accuracy vs loss (alpha={best_alpha})', fontsize=14)\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "        plt.tight_layout()\n",
        "        out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__acc_vs_loss.png\"\n",
        "        plt.savefig(out_png_path, dpi=100, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Accuracy vs loss plot saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Persist Metrics\n",
        "\n",
        "将指标保存到指定的JSON文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create metrics dictionary\n",
        "metrics_dict = {\n",
        "    \"model_name\": \"SGD Classifier\",\n",
        "    \"best_hyperparams\": best_params,\n",
        "    \"accuracy\": final_metrics['accuracy'],\n",
        "    \"macro_f1\": final_metrics['macro_f1'],\n",
        "    \"weighted_f1\": final_metrics['weighted_f1'],\n",
        "    \"train_time_sec\": best_training_time,\n",
        "    \"notes\": f\"SGD with loss={best_params['loss']}, alpha={best_params['alpha']} achieved {final_metrics['accuracy']:.4f} accuracy\"\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file\n",
        "metrics_path = f\"../results/metrics/{NOTEBOOK_BASENAME}__metrics.json\"\n",
        "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics_dict, f, indent=2)\n",
        "\n",
        "print(f\"Metrics saved to {metrics_path}\")\n",
        "print(f\"Final metrics: {metrics_dict}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 loss='log_loss'、alpha=0.0001 的 SGD 分类器达到了最佳性能，准确率为 0.9361。\n",
        "本模型对 loss 和 alpha 参数敏感，log 损失配合较小的正则化强度效果最佳。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion (Template)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
