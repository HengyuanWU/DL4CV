{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [DO NOT EDIT] Header\n",
        "\n",
        "本笔记本实现了用于数字分类的决策树模型，包含超参数调优。\n",
        "所有代码必须遵循实现指南中定义的项目结构和命名约定。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# 魔法命令\n",
        "%matplotlib inline\n",
        "\n",
        "# 路径设置 - 导入此模块会自动设置Python路径\n",
        "import path_setup\n",
        "\n",
        "# 直接导入项目模块（IDE可以正确追踪）\n",
        "from load_data import load_digits_dataset\n",
        "from evaluate import eval_classification, eval_classification_with_roc\n",
        "from visualize import plot_confusion_matrix, plot_bar\n",
        "\n",
        "# Constants\n",
        "RANDOM_STATE = 42\n",
        "NOTEBOOK_BASENAME = \"part4_decision_tree\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(\"../results/figures\", exist_ok=True)\n",
        "os.makedirs(\"../results/metrics\", exist_ok=True)\n",
        "\n",
        "print(\"✓ 环境设置完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Loading\n",
        "\n",
        "使用提供的API函数加载数字数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the digits dataset\n",
        "X_train, X_test, y_train, y_test, target_names = load_digits_dataset()\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of classes: {len(target_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition (Default Only)\n",
        "\n",
        "仅定义一个模型实例，使用库默认参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define default model with library defaults\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "default_model = DecisionTreeClassifier(\n",
        "    random_state=RANDOM_STATE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Default Model)\n",
        "\n",
        "对默认参数模型执行训练，记录训练用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the default model\n",
        "start_time = time.time()\n",
        "default_model.fit(X_train, y_train)\n",
        "default_training_time = time.time() - start_time\n",
        "print(f\"Default model training time: {default_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Default Model)\n",
        "\n",
        "评估默认模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the default model\n",
        "default_metrics = eval_classification(default_model, X_test, y_test, target_names)\n",
        "print(f\"Default model accuracy: {default_metrics['accuracy']:.4f}\")\n",
        "print(f\"Default model macro F1: {default_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Default model weighted F1: {default_metrics['weighted_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Default Model)\n",
        "\n",
        "可视化默认模型结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix for default model\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_default.png\"\n",
        "plot_confusion_matrix(default_metrics['confusion_matrix'], target_names, out_png_path)\n",
        "print(f\"Default model confusion matrix saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fill Hyperparams (Tuning Spec)\n",
        "\n",
        "定义调参网格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grid for Decision Tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define base model with stability parameters\n",
        "base_model = DecisionTreeClassifier(\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Define parameter grid (strictly follow Canvas Chapter 4)\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 9, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "gs = GridSearchCV(\n",
        "    estimator=base_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Execute grid search\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and CV score\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"Best CV score (accuracy):\", gs.best_score_)\n",
        "\n",
        "# Get best model and evaluate on test set\n",
        "best_model = gs.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)\n",
        "print(\"Test accuracy with best params:\", test_acc)\n",
        "\n",
        "# Save variables for later use\n",
        "model = best_model\n",
        "best_params = gs.best_params_\n",
        "best_training_time = gs.cv_results_['mean_fit_time'][gs.best_index_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training (Tuned Model)\n",
        "\n",
        "使用最佳参数实例化第二个模型对象并训练，记录用时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the best model (already done during grid search)\n",
        "print(f\"Best model trained with hyperparameters: {best_params}\")\n",
        "print(f\"Training time: {best_training_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation (Tuned Model)\n",
        "\n",
        "评估调参后模型性能。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the best model\n",
        "final_metrics = eval_classification(best_model, X_test, y_test, target_names)\n",
        "\n",
        "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {final_metrics['macro_f1']:.4f}\")\n",
        "print(f\"Weighted F1: {final_metrics['weighted_f1']:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(final_metrics['classification_report'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization (Tuned Model + Param Curves)\n",
        "\n",
        "可视化调参后模型结果和性能曲线。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ① Plot confusion matrix for tuned model\n",
        "cm = final_metrics['confusion_matrix']\n",
        "out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__cm_tuned.png\"\n",
        "plot_confusion_matrix(cm, target_names, out_png_path)\n",
        "print(f\"Tuned model confusion matrix saved to {out_png_path}\")\n",
        "\n",
        "# ② Plot parameter performance curves\n",
        "cv_results = gs.cv_results_\n",
        "params_list = cv_results[\"params\"]\n",
        "mean_test = cv_results[\"mean_test_score\"]\n",
        "\n",
        "# Plot each parameter\n",
        "for param_key in param_grid.keys():\n",
        "    if param_key == 'max_depth':\n",
        "        # Use best min_samples_split\n",
        "        best_mss = best_params['min_samples_split']\n",
        "        depth_vals = []\n",
        "        scores = []\n",
        "        for i, params in enumerate(params_list):\n",
        "            if params['min_samples_split'] == best_mss:\n",
        "                depth_vals.append(params['max_depth'])\n",
        "                scores.append(mean_test[i])\n",
        "        \n",
        "        # Sort, handling None\n",
        "        def sort_key(x):\n",
        "            return (999 if x[0] is None else x[0])\n",
        "        sorted_pairs = sorted(zip(depth_vals, scores), key=sort_key)\n",
        "        depth_vals_sorted = [p[0] for p in sorted_pairs]\n",
        "        scores_sorted = [p[1] for p in sorted_pairs]\n",
        "        \n",
        "        # Convert None to string for plotting\n",
        "        depth_labels = [str(d) if d is not None else 'None' for d in depth_vals_sorted]\n",
        "        x_positions = range(len(depth_labels))\n",
        "        \n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.plot(x_positions, scores_sorted, marker='o', linewidth=2, markersize=8)\n",
        "        ax.set_xticks(x_positions)\n",
        "        ax.set_xticklabels(depth_labels)\n",
        "        ax.set_xlabel('max_depth', fontsize=12)\n",
        "        ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "        ax.set_title(f'Decision Tree: Accuracy vs max_depth (min_samples_split={best_mss})', fontsize=14)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__acc_vs_max_depth.png\"\n",
        "        plt.savefig(out_png_path, dpi=100, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Accuracy vs max_depth plot saved to {out_png_path}\")\n",
        "    \n",
        "    elif param_key == 'min_samples_split':\n",
        "        # Use best max_depth\n",
        "        best_depth = best_params['max_depth']\n",
        "        mss_vals = []\n",
        "        scores = []\n",
        "        for i, params in enumerate(params_list):\n",
        "            if params['max_depth'] == best_depth:\n",
        "                mss_vals.append(params['min_samples_split'])\n",
        "                scores.append(mean_test[i])\n",
        "        \n",
        "        # Sort\n",
        "        sorted_pairs = sorted(zip(mss_vals, scores))\n",
        "        mss_vals_sorted = [p[0] for p in sorted_pairs]\n",
        "        scores_sorted = [p[1] for p in sorted_pairs]\n",
        "        \n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.plot(mss_vals_sorted, scores_sorted, marker='o', linewidth=2, markersize=8)\n",
        "        ax.set_xlabel('min_samples_split', fontsize=12)\n",
        "        ax.set_ylabel('Cross-Validation Accuracy', fontsize=12)\n",
        "        ax.set_title(f'Decision Tree: Accuracy vs min_samples_split (max_depth={best_depth})', fontsize=14)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        out_png_path = f\"../results/figures/{NOTEBOOK_BASENAME}__acc_vs_min_samples_split.png\"\n",
        "        plt.savefig(out_png_path, dpi=100, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Accuracy vs min_samples_split plot saved to {out_png_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Persist Metrics\n",
        "\n",
        "将指标保存到指定的JSON文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create metrics dictionary\n",
        "metrics_dict = {\n",
        "    \"model_name\": \"Decision Tree\",\n",
        "    \"best_hyperparams\": best_params,\n",
        "    \"accuracy\": final_metrics['accuracy'],\n",
        "    \"macro_f1\": final_metrics['macro_f1'],\n",
        "    \"weighted_f1\": final_metrics['weighted_f1'],\n",
        "    \"train_time_sec\": best_training_time,\n",
        "    \"notes\": f\"Decision Tree with max_depth={best_params['max_depth']}, min_samples_split={best_params['min_samples_split']} achieved {final_metrics['accuracy']:.4f} accuracy\"\n",
        "}\n",
        "\n",
        "# Save metrics to JSON file\n",
        "metrics_path = f\"../results/metrics/{NOTEBOOK_BASENAME}__metrics.json\"\n",
        "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics_dict, f, indent=2)\n",
        "\n",
        "print(f\"Metrics saved to {metrics_path}\")\n",
        "print(f\"Final metrics: {metrics_dict}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 max_depth=9、min_samples_split=2 的决策树达到了最佳性能，准确率为 0.8528。\n",
        "本模型对 max_depth 参数敏感，适中的树深度在该数据集上效果更好。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion (Template)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
